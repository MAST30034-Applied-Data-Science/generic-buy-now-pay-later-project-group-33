{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbc6ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "407a3036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 2\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abeee62",
   "metadata": {},
   "source": [
    "# 1.Read the data in and check the presence of null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b4e3b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function used to check the presence of null values.\n",
    "def check_null_value(dataframe):\n",
    "    for columns in dataframe.columns:\n",
    "        print('Number of null value in', columns, ':', dataframe.where(F.col(columns).isNull()).count())\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17c170a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null value in user_id : 0\n",
      "Number of null value in consumer_id : 0\n"
     ]
    }
   ],
   "source": [
    "consumer_id = spark.read.parquet('../data/tables/consumer_user_details.parquet')\n",
    "check_null_value(consumer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a54adcee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null value in name : 0\n",
      "Number of null value in address : 0\n",
      "Number of null value in state : 0\n",
      "Number of null value in postcode : 0\n",
      "Number of null value in gender : 0\n",
      "Number of null value in consumer_id : 0\n"
     ]
    }
   ],
   "source": [
    "# Use pandas read consumer csv\n",
    "raw_consumer_df = spark.read.option(\"header\",True).csv('../data/tables/tbl_consumer.csv')\n",
    "check_null_value(raw_consumer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69d18a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null value in merchant_name : 0\n",
      "Number of null value in tags : 0\n",
      "Number of null value in merchant_abn : 0\n"
     ]
    }
   ],
   "source": [
    "merchant_df = spark.read.parquet('../data/tables/tbl_merchants.parquet').withColumnRenamed('name','merchant_name')\n",
    "check_null_value(merchant_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acbbc1c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null value in user_id : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null value in merchant_abn : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null value in dollar_value : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 231:====================================================>  (21 + 1) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null value in order_id : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "path_list = []\n",
    "period1 = pd.date_range('2021-2-28','2021-08-27', freq='D').strftime(\"%Y-%m-%d\").tolist()\n",
    "period2 = pd.date_range('2021-8-28','2022-02-27', freq='D').strftime(\"%Y-%m-%d\").tolist()\n",
    "period3 = pd.date_range('2022-2-28','2022-08-28', freq='D').strftime(\"%Y-%m-%d\").tolist()\n",
    "path_prefix1 = '../data/tables/transactions_20210228_20210827_snapshot/order_datetime='\n",
    "path_prefix2 = '../data/tables/transactions_20210828_20220227_snapshot/order_datetime='\n",
    "path_prefix3 = '../data/tables/transactions_20220228_20220828_snapshot/order_datetime='\n",
    "for date in period1:\n",
    "    path_list.append(path_prefix1 + date)\n",
    "for date in period2:\n",
    "    path_list.append(path_prefix2 + date)\n",
    "for date in period3:\n",
    "    path_list.append(path_prefix3 + date)\n",
    "\n",
    "raw_transactions_df = spark.read.parquet(*path_list)\n",
    "\n",
    "check_null_value(raw_transactions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4cfa97",
   "metadata": {},
   "source": [
    "#### No null value is found in the raw datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5b798d",
   "metadata": {},
   "source": [
    "# 2. Data aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b3a9c2",
   "metadata": {},
   "source": [
    "First, we aggregate the given consumer, merchant and transactions data, drop the irrelevant features for the ranking system such as consumers' id and name, transactions' order id and merchants' abn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92362397",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_df =  consumer_id.join(raw_consumer_df, consumer_id.consumer_id == raw_consumer_df.consumer_id, 'inner')\\\n",
    "                            .withColumnRenamed('name','consumer_name')\\\n",
    "                            .withColumnRenamed('address','consumer_address')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f834336",
   "metadata": {},
   "source": [
    "Get the take rate of each merchant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92301d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_df = merchant_df.withColumn('tags_string', split(merchant_df['tags'], ':'))\\\n",
    "                         .withColumn('rate_string', element_at(col('tags_string'), -1))\\\n",
    "                         .withColumn('rate_substring', substring('rate_string', 1, 5))\\\n",
    "                         .withColumn('take_rate', col('rate_substring').cast('double'))\\\n",
    "                         .drop('rate_string', 'rate_substring', 'tags_string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b6163b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = raw_transactions_df.join(merchant_df, raw_transactions_df.merchant_abn == merchant_df.merchant_abn, 'inner')\\\n",
    "                           .join(consumer_df, raw_transactions_df.user_id == consumer_df.user_id, 'inner')\\\n",
    "                           .drop('consumer_id', 'consumer_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "230d9dc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12561377, 12047317)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_transactions_df.count(), transactions_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e7a0e4",
   "metadata": {},
   "source": [
    "Since some merchant abns from the transaction data do not match with any merchant from the merchant, we should remove them by inner join with the merchant dataset. About  5% of data are eliminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fcf6d683",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>tags</th></tr>\n",
       "<tr><td>([florists suppli...</td></tr>\n",
       "<tr><td>[[gift, Card, nov...</td></tr>\n",
       "<tr><td>([gifT, card, nov...</td></tr>\n",
       "<tr><td>([tent and awning...</td></tr>\n",
       "<tr><td>[(digital goods: ...</td></tr>\n",
       "<tr><td>[(shoe shops), (a...</td></tr>\n",
       "<tr><td>[(computer progra...</td></tr>\n",
       "<tr><td>[(digital goods: ...</td></tr>\n",
       "<tr><td>[[stationery, off...</td></tr>\n",
       "<tr><td>[(optIcians, opti...</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+\n",
       "|                tags|\n",
       "+--------------------+\n",
       "|([florists suppli...|\n",
       "|[[gift, Card, nov...|\n",
       "|([gifT, card, nov...|\n",
       "|([tent and awning...|\n",
       "|[(digital goods: ...|\n",
       "|[(shoe shops), (a...|\n",
       "|[(computer progra...|\n",
       "|[(digital goods: ...|\n",
       "|[[stationery, off...|\n",
       "|[(optIcians, opti...|\n",
       "+--------------------+"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_df.limit(10).select('tags')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11eeae9",
   "metadata": {},
   "source": [
    "We compute the total income, the number of transactions, the mean transaction amount and the profit for each merchant for the preliminary analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43876e2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Reference 'user_id' is ambiguous, could be: user_id, user_id.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m merchant_detail \u001b[38;5;241m=\u001b[39m \u001b[43mtransactions_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupBy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmerchant_abn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmerchant_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtake_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdollar_value\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtotal_income\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmerchant_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtotal_transactions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\\\n\u001b[1;32m      5\u001b[0m                   \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_transaction_amount\u001b[39m\u001b[38;5;124m'\u001b[39m,  F\u001b[38;5;241m.\u001b[39mround(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_income\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m/\u001b[39mF\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_transactions\u001b[39m\u001b[38;5;124m'\u001b[39m)))\\\n\u001b[1;32m      6\u001b[0m                   \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonthly_profit\u001b[39m\u001b[38;5;124m'\u001b[39m,  F\u001b[38;5;241m.\u001b[39mround(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_income\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m*\u001b[39mF\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtake_rate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m18\u001b[39m))\\\n\u001b[1;32m      7\u001b[0m                   \u001b[38;5;241m.\u001b[39morderBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonthly_profit\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/group.py:137\u001b[0m, in \u001b[0;36mGroupedData.agg\u001b[0;34m(self, *exprs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(c, Column) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m exprs), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall exprs should be Column\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m     exprs \u001b[38;5;241m=\u001b[39m cast(Tuple[Column, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], exprs)\n\u001b[0;32m--> 137\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jgd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexprs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexprs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Reference 'user_id' is ambiguous, could be: user_id, user_id."
     ]
    }
   ],
   "source": [
    "merchant_detail = transactions_df.groupBy('user_id', 'merchant_abn', 'merchant_name', 'tags', 'take_rate')\\\n",
    "                  .agg(\n",
    "                       F.round(F.sum('dollar_value'),2).alias('total_income'),\n",
    "                       F.count('merchant_name').alias('total_transactions'), )\\\n",
    "                  .withColumn('mean_transaction_amount',  F.round(F.col('total_income')/F.col('total_transactions')))\\\n",
    "                  .withColumn('monthly_profit',  F.round(F.col('total_income')*F.col('take_rate')/100/18))\\\n",
    "                  .orderBy('monthly_profit', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc37e4be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merchant_detail.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3570cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_detail.count(), merchant_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75573b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed data\n",
    "transactions_df.write.mode('overwrite').parquet('../data/curated/transactions_detail.parquet')\n",
    "merchant_detail.write.mode('overwrite').parquet('../data/curated/merchant_detail.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce96ef9",
   "metadata": {},
   "source": [
    "# 3. Preliminarily check distribution of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692e1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins, counts = merchant_detail.select('monthly_profit').rdd.flatMap(lambda x: x).histogram(200)\n",
    "plt.hist(bins[:-1], bins=bins, weights=counts)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('monthly_profit (dollar)')\n",
    "plt.title('Histogram graph of monthly profit')\n",
    "plt.savefig('../plots/Histogram graph of monthly profit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cef7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins, counts = merchant_detail.select('total_transactions').rdd.flatMap(lambda x: x).histogram(200)\n",
    "plt.hist(bins[:-1], bins=bins, weights=counts)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('transaction frequency')\n",
    "plt.title('Histogram graph of total transactions')\n",
    "plt.savefig('../plots/Histogram graph of total transactions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8393fc7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bins, counts = merchant_detail.select('mean_transaction_amount').rdd.flatMap(lambda x: x).histogram(200)\n",
    "plt.hist(bins[:-1], bins=bins, weights=counts)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('mean transaction (dollar)')\n",
    "plt.title('Histogram graph of mean transaction amount')\n",
    "plt.savefig('../plots/Histogram graph of mean transaction amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fa2c14",
   "metadata": {},
   "source": [
    "There are some extremely large values, outliers elimination and data transformation may be needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
